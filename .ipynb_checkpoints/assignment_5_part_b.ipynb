{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "assignment_5_part_b-checkpoint.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SogY7a69yHFj"
      },
      "source": [
        "# To get access to the dataset:\n",
        "- If you already have the folder with the datasets, you might need to 'git pull' to ensure that it is updated\n",
        "> Else, clone repo using the command below <br>\n",
        "> \"git clone https://github.com/clemnyan/ENGS_108_Fall_2021.git\" <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWeOBUd1n2IC"
      },
      "source": [
        "**ENGS 108 Assignment 5 Checkpoint B**\n",
        "\n",
        "Teshie Bronk \n",
        "\n",
        "Professor Cybenko\n",
        "\n",
        "October 19, 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8uBU28enwi6",
        "outputId": "050f7537-a8cb-4bca-be48-d5f5fdc025cc"
      },
      "source": [
        "!git clone https://github.com/clemnyan/ENGS_108_Fall_2021.git "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ENGS_108_Fall_2021'...\n",
            "remote: Enumerating objects: 989, done.\u001b[K\n",
            "remote: Counting objects: 100% (989/989), done.\u001b[K\n",
            "remote: Compressing objects: 100% (948/948), done.\u001b[K\n",
            "remote: Total 989 (delta 42), reused 971 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (989/989), 77.54 MiB | 20.93 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITP8evQ-oEkP"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uBE3mbcyHFl"
      },
      "source": [
        "## **Problem 2: Introduction to TensorFlow**\n",
        "In this problem, we will start working in tensorflow to build deep learning systems starting with fully connected neural networks. We will focus on using the food image dataset we built in the last problem.\n",
        ">\n",
        "> **(a)** Using the food image dataset we built in the last problem (last week's assignment!), build a [tensorflow Data Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) that is shuffled with a batch size of 10. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APZQpgKuyHFl",
        "outputId": "220fb5c7-73d3-4d5e-e186-2db34170724d"
      },
      "source": [
        "# Code and explanation\n",
        "path = '/content/ENGS_108_Fall_2021/datasets/ExampleFoodImageDataset'\n",
        "\n",
        "#create training set\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  path,\n",
        "  validation_split=0.2, #80% in training\n",
        "  subset=\"training\", #training set\n",
        "  seed=123, #set seed\n",
        "  image_size=(28, 28), #resize\n",
        "  batch_size=10) #set batch size\n",
        "\n",
        "#create validation set\n",
        "valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  path,\n",
        "  validation_split=0.2, #20% in validation\n",
        "  subset=\"validation\", #validation set\n",
        "  seed=123, #set seed\n",
        "  image_size=(28, 28), #resize image\n",
        "  batch_size=10) #batch size\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 978 files belonging to 9 classes.\n",
            "Using 783 files for training.\n",
            "Found 978 files belonging to 9 classes.\n",
            "Using 195 files for validation.\n",
            "['caesar_salad', 'caprese_salad', 'french_fries', 'greek_salad', 'hamburger', 'hot_dog', 'pizza', 'sashimi', 'sushi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEpOU-eryHFm"
      },
      "source": [
        "> **(b)** Build a two layer fully connected neural network of any size with a ReLu activation function and a final softmax layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbItCp4GwkhC",
        "outputId": "695676e9-ee02-47e4-d0f8-0582bbc1f398"
      },
      "source": [
        "#inspect image sets and ensure they're the correct size \n",
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break\n",
        "#our batches are of 10 with images of 28x28x3"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 28, 28, 3)\n",
            "(10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTaFKAyXyP5b"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "#applying cache() and prefetch helps improve performance of neural net\n",
        "#additional documentation here: https://www.tensorflow.org/tutorials/load_data/images\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_ds = valid_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a71bUHKyyHFm"
      },
      "source": [
        "#Creating a two layer fully connected neural network \n",
        "#to clarify, I interpreted this question as asking for ReLu, softmax, AND 2 additional layers\n",
        "\n",
        "#number of classes\n",
        "num_classes = 9\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255), #just rescaling from 0-->255 for rgb to 0-->1\n",
        "  tf.keras.layers.Dense(128, activation='relu'), #dense layer with 128 neurons, relu activation\n",
        "  tf.keras.layers.Flatten(), #flatten it out to 784 (ie. long vector of all pixels)\n",
        "  tf.keras.layers.Dense(10, activation='softmax') #softmax layer with 10 neurons. \n",
        "  #Creates probability distrib = 1 with probabilities for each of the classes\n",
        "  ])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLqjII8JyHFm"
      },
      "source": [
        "> **(c)** Compile your model with an appropriate loss function and optimizer. Briefly describe your choices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQK9k7nR0eKW"
      },
      "source": [
        "#indicates optimizer, loss function, and metric for assessing model performance\n",
        "model.compile(\n",
        "  optimizer='adam', \n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy']) "
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f-p13a9FdZ_"
      },
      "source": [
        "Updates model in response to particular loss function that we've chosen. The optimizer in this case, adam, uses a nonconstant learning rate. Adam also performs well in terms of memory usage, and general efficiency. Similarly, we are using a categorical cross entropy loss function here which computes the loss in accordance with the negative log of the probability of the correct classification. Ie. if probability of correct classification is 1 then loss is zero but if it's small (like 0.1) then the loss is higher - ie. further correcting the network. In turn, this lets for robust model fitting when there are number of classification options. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJQ3aNWxyHFn"
      },
      "source": [
        "> **(d)** Train your model on the food image training dataset. And report your accuracy on the testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U46nv6d0jCD",
        "outputId": "54b43b2d-b41c-4383-f70b-537a24fd6b6f"
      },
      "source": [
        "#fit the model of training data and assess on validation\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=valid_ds,\n",
        "  epochs=12\n",
        ")"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:4907: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 2s 18ms/step - loss: 1.9065 - accuracy: 0.3550 - val_loss: 1.9314 - val_accuracy: 0.2974\n",
            "Epoch 2/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 1.2588 - accuracy: 0.5556 - val_loss: 1.9785 - val_accuracy: 0.3128\n",
            "Epoch 3/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.9784 - accuracy: 0.6501 - val_loss: 1.9952 - val_accuracy: 0.3590\n",
            "Epoch 4/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.7550 - accuracy: 0.7471 - val_loss: 2.0586 - val_accuracy: 0.3795\n",
            "Epoch 5/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.5738 - accuracy: 0.8314 - val_loss: 2.1375 - val_accuracy: 0.3897\n",
            "Epoch 6/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.4359 - accuracy: 0.8914 - val_loss: 2.1106 - val_accuracy: 0.4462\n",
            "Epoch 7/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.3627 - accuracy: 0.9195 - val_loss: 2.0193 - val_accuracy: 0.4667\n",
            "Epoch 8/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.3112 - accuracy: 0.9208 - val_loss: 2.1907 - val_accuracy: 0.4205\n",
            "Epoch 9/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.2617 - accuracy: 0.9323 - val_loss: 2.3883 - val_accuracy: 0.4051\n",
            "Epoch 10/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.2318 - accuracy: 0.9425 - val_loss: 2.3991 - val_accuracy: 0.4359\n",
            "Epoch 11/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.2223 - accuracy: 0.9361 - val_loss: 2.2201 - val_accuracy: 0.5128\n",
            "Epoch 12/12\n",
            "79/79 [==============================] - 1s 17ms/step - loss: 0.2004 - accuracy: 0.9502 - val_loss: 2.1888 - val_accuracy: 0.5128\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2bb00d4190>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah39dzbQPZcj"
      },
      "source": [
        "Compiling over 12 epochs our neural net has a training accuracy of 0.95 and validation accuracy of 51.28%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO0yejS6yHFo"
      },
      "source": [
        "> **(e)** Now try to tune this network by varying the number of layers, units, activations and see if you can outperform the network in part (d). Does your best model perform better or worse than the SVM in problem 1?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3bGtadJyHFo"
      },
      "source": [
        "# Code and explanation\n",
        "\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1./127.5, offset = -1),\n",
        "  tf.keras.layers.Conv2D(32,3, activation='relu', use_bias = 'true'),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(num_classes, activation= 'softmax')\n",
        "  ])"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlXl-UPAUMrh"
      },
      "source": [
        "#indicates optimizer, loss function, and metric for assessing model performance\n",
        "model_2.compile(\n",
        "  optimizer='adam', \n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy']) "
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pCj1FMcTmGH",
        "outputId": "abd376ec-09e0-43e4-c8bc-a3036af4e4d4"
      },
      "source": [
        "#fit the model of training data and assess on validation\n",
        "model_2.fit(\n",
        "  train_ds,\n",
        "  validation_data = valid_ds,\n",
        "  epochs=12\n",
        ")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:4907: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 14ms/step - loss: 1.7425 - accuracy: 0.3512 - val_loss: 1.9220 - val_accuracy: 0.2564\n",
            "Epoch 2/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 1.3261 - accuracy: 0.5236 - val_loss: 1.8061 - val_accuracy: 0.2923\n",
            "Epoch 3/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.9928 - accuracy: 0.6437 - val_loss: 1.7990 - val_accuracy: 0.4000\n",
            "Epoch 4/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.7032 - accuracy: 0.7791 - val_loss: 1.8703 - val_accuracy: 0.4205\n",
            "Epoch 5/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.4691 - accuracy: 0.8646 - val_loss: 2.0680 - val_accuracy: 0.4308\n",
            "Epoch 6/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.3069 - accuracy: 0.9349 - val_loss: 2.0875 - val_accuracy: 0.4769\n",
            "Epoch 7/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.2105 - accuracy: 0.9617 - val_loss: 2.1814 - val_accuracy: 0.4615\n",
            "Epoch 8/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.1632 - accuracy: 0.9732 - val_loss: 2.3791 - val_accuracy: 0.4564\n",
            "Epoch 9/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.1933 - accuracy: 0.9502 - val_loss: 2.4670 - val_accuracy: 0.4564\n",
            "Epoch 10/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.3170 - accuracy: 0.8902 - val_loss: 2.0944 - val_accuracy: 0.5026\n",
            "Epoch 11/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.2007 - accuracy: 0.9374 - val_loss: 2.3196 - val_accuracy: 0.4974\n",
            "Epoch 12/12\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.1098 - accuracy: 0.9808 - val_loss: 2.4737 - val_accuracy: 0.4974\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2bb78ccc10>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smYBaxrrR8vD"
      },
      "source": [
        "For this updated network, I added a number of layers to increase the network complexity. First, I tried adding 3 series of convolutional 2d layers followed by max pooling layers. The purpose of doing this was to extract certain features from the images with the convolutional layers then pass that through a max pooling layer to enhance those particular features. Furthermore, by having iterated layers, we ideally would have multiple steps in which we chose those relevant features and enhanced them to have a clear portrayal of what features are most important for classification. I also altered the filter size, though this did not have a significant effect on classification accuracy. Finally, I included a flatten layer to flatten the pixels as I did in the previous model and implemented two more dense layers with narrowing numbers of neurons (128-->9) and a final softmax layer. \n",
        "\n",
        "Additionally, I also messed with the activation function type (from relu to sigmoid, etc.) but this did not have a large effect. Changing the loss function and optimizer also didn't have a significant effect given that the adam optimizer and cross entropy class. are pretty robust methods.\n",
        "\n",
        "In my first setup with 3 series of Conv2D+maxpooling layers, my validation accruacy (~40%) was low so I went back to just one set of Conv2D+maxpool. I also dropped one of the final dense layers.\n",
        "\n",
        "In this slightly more complex model than that used in d), our validation accuracy after 12 epochs was 0.4974 and training accuracy of 0.98. In turn, despite trying a number of more complex models, it appears as though adding convolutional layers, maxpool layers, and other dense layers, does not actually improve model accuracy as the network tends to just overfit the training data. Rather, it appears as though some kind of more niche network that can pick on relevant features without overfitting or more simply, a simple model like that in part d) performs equally well for classifying the images. \n",
        "\n",
        "Interestingly, this network accuracy is incredibly similar to that which was determined in the previous homework in which we built a classifier with a SVM. I think that's quite interesting given that the neural net should pick up on image features much more easily and identify those that are especially relevant. Perhaps we need to explore some more neural net structures for image classifcation later on in the term to have improved detection of particular images!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6fKFBUdyHFp"
      },
      "source": [
        "> **(BONUS)** We lost a lot of information when we resized the images in part (a). What would happen if we didn't resize the images and we built fit the neural network with all this other information? Try it out! *Hint: Runtime will be much longer, both to create the image dataset without resizing and to train the model, so you might have to get the code working and then just let it run.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhPzp9s2QEFt"
      },
      "source": [
        "If we didn't resize the images and built and fit the network with the entire images, we'd have much higher accuracy as there would be far more distinct features for our network to recognize in each image and pick up on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VNEv-vMyHFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f8584b-871f-4c8d-f79a-fe95a8247483"
      },
      "source": [
        "#example for the bonus\n",
        "#import without resize\n",
        "path = '/content/ENGS_108_Fall_2021/datasets/ExampleFoodImageDataset'\n",
        "\n",
        "#create training set\n",
        "train_ds_not_re = tf.keras.utils.image_dataset_from_directory(\n",
        "  path,\n",
        "  validation_split=0.2, #80% in training\n",
        "  subset=\"training\", #training set\n",
        "  seed=123, #set seed\n",
        "  batch_size=10) #set batch size\n",
        "\n",
        "#create validation set\n",
        "valid_ds_not_re = tf.keras.utils.image_dataset_from_directory(\n",
        "  path,\n",
        "  validation_split=0.2, #20% in validation\n",
        "  subset=\"validation\", #validation set\n",
        "  seed=123, #set seed\n",
        "  batch_size=10) #batch size\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 978 files belonging to 9 classes.\n",
            "Using 783 files for training.\n",
            "Found 978 files belonging to 9 classes.\n",
            "Using 195 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUng-1_MbMCL"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "#applying cache() and prefetch helps improve performance of neural net\n",
        "#additional documentation here: https://www.tensorflow.org/tutorials/load_data/images\n",
        "train_ds = train_ds_not_re.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "valid_ds = valid_ds_not_re.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU-sToFwbMvl"
      },
      "source": [
        "#Creating a two layer fully connected neural network \n",
        "#to clarify, I interpreted this question as asking for ReLu, softmax, AND 2 additional layers\n",
        "\n",
        "#number of classes\n",
        "num_classes = 9\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255), #just rescaling from 0-->255 for rgb to 0-->1\n",
        "  tf.keras.layers.Dense(128, activation='relu'), #dense layer with 128 neurons, relu activation\n",
        "  tf.keras.layers.Flatten(), #flatten it out to 784 (ie. long vector of all pixels)\n",
        "  tf.keras.layers.Dense(10, activation='softmax') #softmax layer with 10 neurons. \n",
        "  #Creates probability distrib = 1 with probabilities for each of the classes\n",
        "  ])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WqRtfNIbSJV"
      },
      "source": [
        "#indicates optimizer, loss function, and metric for assessing model performance\n",
        "model.compile(\n",
        "  optimizer='adam', \n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy']) "
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_59qPAhNbO2g",
        "outputId": "26b224be-0e4c-4296-a381-f72f778929e1"
      },
      "source": [
        "#fit the model of training data and assess on validation\n",
        "model.fit(\n",
        "  train_ds_not_re,\n",
        "  validation_data=valid_ds_not_re,\n",
        "  epochs=4\n",
        ")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:4907: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 98s 1s/step - loss: 124.0187 - accuracy: 0.2989 - val_loss: 22.6991 - val_accuracy: 0.2564\n",
            "Epoch 2/4\n",
            "79/79 [==============================] - 93s 1s/step - loss: 8.5637 - accuracy: 0.5147 - val_loss: 13.7341 - val_accuracy: 0.3744\n",
            "Epoch 3/4\n",
            "79/79 [==============================] - 92s 1s/step - loss: 2.1551 - accuracy: 0.7446 - val_loss: 7.0795 - val_accuracy: 0.4564\n",
            "Epoch 4/4\n",
            "79/79 [==============================] - 92s 1s/step - loss: 0.8912 - accuracy: 0.8429 - val_loss: 5.3317 - val_accuracy: 0.4615\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2bb771d210>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c3FsUqNdkuI"
      },
      "source": [
        "I only trained this network for four epochs as the training time was significantly higher for these non-resized images. We did achieve a validation accuracy of 46% after these four epochs which is infact better than that of the previous two models after 4 epochs. In turn, it appears as though this network is performing somewhat better than the previous models trained on resized images, though this difference is not especially stark or significant. Indeed, a different network structure is likely needed to more accurately classify these particular images. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p827klpeyHFp"
      },
      "source": [
        "> **(BONUS)** Implement and explain other feature engineering (and data augmentation) techniques that we can perform to increase prediction accuracy? "
      ]
    }
  ]
}