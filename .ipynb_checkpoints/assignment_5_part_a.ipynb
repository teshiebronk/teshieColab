{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "assignment_5_part_a-checkpoint.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irIDq-8hecIP"
      },
      "source": [
        "# To get access to the dataset:\n",
        "- Clone repo using the command below <br>\n",
        "- \"git clone https://github.com/clemnyan/ENGS_108_Fall_2021.git\" <br>\n",
        "- all datasets are located in the \"datasets\" folder of the cloned repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6K3zS6Leq5k",
        "outputId": "ef3f1a4b-7995-4d66-ea30-9abdd60bef36"
      },
      "source": [
        "!git clone https://github.com/clemnyan/ENGS_108_Fall_2021.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ENGS_108_Fall_2021'...\n",
            "remote: Enumerating objects: 989, done.\u001b[K\n",
            "remote: Counting objects: 100% (989/989), done.\u001b[K\n",
            "remote: Compressing objects: 100% (948/948), done.\u001b[K\n",
            "remote: Total 989 (delta 42), reused 971 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (989/989), 77.54 MiB | 36.39 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyCSgKafecIQ"
      },
      "source": [
        "## **Problem 1: Support Vector Machines**\n",
        "In this problem, you will be building a support vector machines to for both regression and classification tasks.\n",
        ">\n",
        "> **Part 1** In this part we will be exploring the *circles* dataset. In this dataset you will have an $X$ array of 2 dimensional samples of the form $(x_1, x_2)$ and a $y$ array of each samples associated label. \n",
        ">> **(a)** Go through the circles dataset and create a scatterplot of the circles data using the y label of each samples color to designate their respective class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f78gCgSecIQ",
        "outputId": "4e036815-1cfb-4acc-9394-97b1bc83a90d"
      },
      "source": [
        "#Code and explanation for 1a\n",
        "\n",
        "#loading data \n",
        "import pickle  #check documentation to open pickled file\n",
        "import pandas as pd\n",
        "circles = pd.read_pickle(r'/content/ENGS_108_Fall_2021/datasets/circles.pk')\n",
        "#print(circles)\n",
        "#dff[0]\n",
        "#dff.plot.scatter(dff[0], dff[1])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/internals/construction.py:305: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  values = np.array([convert(v) for v in values])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [[0.23733469017483855, 1.1780601257470134], [-...\n",
              "1    [0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, ...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOVZuxUUecIR"
      },
      "source": [
        ">> **(b)** Is this dataset linearly seperable? Explain why or why not?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Qp2a5WecIR"
      },
      "source": [
        "#Code and explanation for 1b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ3-uCJHecIR"
      },
      "source": [
        ">> **(c)** Can you think of a transformation of the dataset that could make the dataset linearly seperable? If so, define what these transformation function(s) might look like, and if not explain why. *Hint: Think of a higher dimensional space.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zk5ux5decIR"
      },
      "source": [
        "#Code and explanation for 1c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZThlW88ecIS"
      },
      "source": [
        ">> **(d)** If you where able to find a transformation in (c), create a suitable graph showing the dataset is linearly seperable in this new feature space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP_qhvNKecIS"
      },
      "source": [
        "#Code and explanation for 1d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3cNOkyGecIT"
      },
      "source": [
        "> **Part 2** What we accomplished in Part 1 is known as the kernel trick for SVMs. Now let's focus on how we can use this idea to accomplish non-linear classification on a real world dataset. In this next part and throughout the remainder of the assignment we will be using a food image dataset. These images are RGB images of many pixels. \n",
        ">> **(a)** You have been given a number of code skeletons throughout the course all of which load and preprocess the data for you. In this excerise tho, we will be doing the data loading manually as it is an important skill to learn. Write some code that will walk through the *ExampleFoodImageDataset* directory structure and build a single large numpy array with all image features flattened into a large vector (Make sure to resize the image to something like (28, 28) or (32, 32), etc.) the first column being a integer id for the class. *Hint: You have been provided with a basic skeleton, study the operations of the code and finish the script.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g67rjMS4ecIT"
      },
      "source": [
        "#Code and explanation for 2a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJFNGSLbecIT"
      },
      "source": [
        ">> **(b)** Split your dataset into training and testing sets with an 80/20 split. *Hint: Look at Sklearn's train_test_split function.* Then implement a SVM classifer and report your accuracy on the testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F9RzlzrecIT"
      },
      "source": [
        "#Code and explanation for 2b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSKWjInHecIU"
      },
      "source": [
        ">> **(c)** Choose a 2 hyperparameters to study and experiment with. Can you make an SVM that has better accuracy then just using the defaults?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A1ciJIwecIU"
      },
      "source": [
        "#Code and explanation for 1c"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}